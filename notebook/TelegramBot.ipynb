{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TelegramBot.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cG8tH4YcSMap","executionInfo":{"status":"ok","timestamp":1620312218851,"user_tz":-120,"elapsed":1830,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"}},"outputId":"2ffb199c-7727-4bd5-e79c-85cd5b8096a2"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KxyVJIpGCpup","executionInfo":{"status":"ok","timestamp":1620312218852,"user_tz":-120,"elapsed":1825,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"}},"outputId":"ce0ae998-1707-4830-a7a8-b6c2ddba291b"},"source":["%cd \"/content/drive/MyDrive/Ingeniaritza Informatikoa/4. Maila/2. Lauhilekoa/HP/Lana/dialbot/notebook\""],"execution_count":3,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: '/content/drive/MyDrive/Ingeniaritza Informatikoa/4. Maila/2. Lauhilekoa/HP/Lana/dialbot/notebook'\n","/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zu9bpmbLSUI2","executionInfo":{"status":"ok","timestamp":1620312218853,"user_tz":-120,"elapsed":1820,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"}},"outputId":"58d595cf-9cab-4310-f678-f9b1a171f57d"},"source":["%cd \"/content/drive/MyDrive/dialbot/notebook\""],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/13R7fsJaBA2ra3u5WI5-hbHRUYUzCn976/dialbot/notebook\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3iuwTfhYNb71","executionInfo":{"status":"ok","timestamp":1620312221519,"user_tz":-120,"elapsed":4480,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"}},"outputId":"024458d5-a18f-4f51-ffbe-7914f25a78d4"},"source":["pip install python-telegram-bot"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: python-telegram-bot in /usr/local/lib/python3.7/dist-packages (13.5)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (2020.12.5)\n","Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (5.1.1)\n","Requirement already satisfied: pytz>=2018.6 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (2018.9)\n","Requirement already satisfied: APScheduler==3.6.3 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (3.6.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (1.15.0)\n","Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (56.0.0)\n","Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (1.5.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UlYR_2YFk2mW","executionInfo":{"status":"ok","timestamp":1620312221519,"user_tz":-120,"elapsed":4479,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"}}},"source":["save_path='token.txt'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"hdYO0XSEkr6N","executionInfo":{"status":"ok","timestamp":1620312221520,"user_tz":-120,"elapsed":4478,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"}}},"source":["with open(save_path) as creds:\n","    for i, line in enumerate(creds):\n","        if i == 1:\n","            TOKEN = line.replace(\"token=\", \"\").replace(\"\\n\", \"\")"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"UPQbW9JCCmhU","executionInfo":{"status":"ok","timestamp":1620312222208,"user_tz":-120,"elapsed":5164,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"}}},"source":["import random\n","from typing import Tuple\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch import Tensor\n","\n","\n","class Encoder(nn.Module):\n","    def __init__(self,\n","                 input_dim: int,\n","                 emb_dim: int,\n","                 enc_hid_dim: int,\n","                 dec_hid_dim: int,\n","                 dropout: float):\n","        super().__init__()\n","\n","        self.input_dim = input_dim\n","        self.emb_dim = emb_dim\n","        self.enc_hid_dim = enc_hid_dim\n","        self.dec_hid_dim = dec_hid_dim\n","        self.dropout = dropout\n","\n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","\n","        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n","\n","        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self,\n","                src: Tensor) -> Tuple[Tensor]:\n","\n","        embedded = self.dropout(self.embedding(src))\n","\n","        outputs, hidden = self.rnn(embedded)\n","\n","        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n","\n","        return outputs, hidden"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"OrlmOMpTCosz","executionInfo":{"status":"ok","timestamp":1620312222209,"user_tz":-120,"elapsed":5163,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"}}},"source":["class Attention(nn.Module):\n","    def __init__(self,\n","                 enc_hid_dim: int,\n","                 dec_hid_dim: int,\n","                 attn_dim: int):\n","        super().__init__()\n","\n","        self.enc_hid_dim = enc_hid_dim\n","        self.dec_hid_dim = dec_hid_dim\n","\n","        self.attn_in = (enc_hid_dim * 2) + dec_hid_dim\n","\n","        self.attn = nn.Linear(self.attn_in, attn_dim)\n","\n","    def forward(self,\n","                decoder_hidden: Tensor,\n","                encoder_outputs: Tensor) -> Tensor:\n","\n","        src_len = encoder_outputs.shape[0]\n","\n","        repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n","\n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","\n","        energy = torch.tanh(self.attn(torch.cat((\n","            repeated_decoder_hidden,\n","            encoder_outputs),\n","            dim = 2)))\n","\n","        attention = torch.sum(energy, dim=2)\n","\n","        return F.softmax(attention, dim=1)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"pbLkV14gCsP0","executionInfo":{"status":"ok","timestamp":1620312222212,"user_tz":-120,"elapsed":5165,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"}}},"source":["class Decoder(nn.Module):\n","    def __init__(self,\n","                 output_dim: int,\n","                 emb_dim: int,\n","                 enc_hid_dim: int,\n","                 dec_hid_dim: int,\n","                 dropout: int,\n","                 attention: nn.Module):\n","        super().__init__()\n","\n","        self.emb_dim = emb_dim\n","        self.enc_hid_dim = enc_hid_dim\n","        self.dec_hid_dim = dec_hid_dim\n","        self.output_dim = output_dim\n","        self.dropout = dropout\n","        self.attention = attention\n","\n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","\n","        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n","\n","        self.out = nn.Linear(self.attention.attn_in + emb_dim, output_dim)\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","\n","    def _weighted_encoder_rep(self,\n","                              decoder_hidden: Tensor,\n","                              encoder_outputs: Tensor) -> Tensor:\n","\n","        a = self.attention(decoder_hidden, encoder_outputs)\n","\n","        a = a.unsqueeze(1)\n","\n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","\n","        weighted_encoder_rep = torch.bmm(a, encoder_outputs)\n","\n","        weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2)\n","\n","        return weighted_encoder_rep, a\n","\n","\n","    def forward(self,\n","                input: Tensor,\n","                decoder_hidden: Tensor,\n","                encoder_outputs: Tensor) -> Tuple[Tensor]:\n","\n","        input = input.unsqueeze(0)\n","\n","        embedded = self.dropout(self.embedding(input))\n","\n","        weighted_encoder_rep, a = self._weighted_encoder_rep(decoder_hidden,\n","                                                          encoder_outputs)\n","\n","        rnn_input = torch.cat((embedded, weighted_encoder_rep), dim = 2)\n","\n","        output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0))\n","\n","        embedded = embedded.squeeze(0)\n","        output = output.squeeze(0)\n","        weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\n","\n","        output = self.out(torch.cat((output,\n","                                     weighted_encoder_rep,\n","                                     embedded), dim = 1))\n","\n","        return output, decoder_hidden.squeeze(0), a.squeeze(1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"X_-VQxpZzSao","executionInfo":{"status":"ok","timestamp":1620312222213,"user_tz":-120,"elapsed":5164,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"}}},"source":["class Seq2Seq(nn.Module):\n","    def __init__(self,\n","                 encoder: nn.Module,\n","                 decoder: nn.Module,\n","                 device: torch.device):\n","        super().__init__()\n","\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","\n","    def forward(self,\n","                src: Tensor,\n","                trg: Tensor,\n","                teacher_forcing_ratio: float = 0.5) -> Tensor:\n","\n","        batch_size = src.shape[1]\n","        max_len = trg.shape[0]\n","        trg_vocab_size = self.decoder.output_dim\n","\n","        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n","\n","        encoder_outputs, hidden = self.encoder(src)\n","\n","        # first input to the decoder is the <sos> token\n","        output = trg[0,:]\n","        for t in range(1, max_len):\n","            output, hidden, _ = self.decoder(output, hidden, encoder_outputs)\n","            outputs[t] = output\n","            teacher_force = random.random() < teacher_forcing_ratio\n","            top1 = output.max(1)[1]\n","            output = (trg[t] if teacher_force else top1)\n","\n","        return outputs"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AJ35JZRnTWU2","executionInfo":{"status":"ok","timestamp":1620312225626,"user_tz":-120,"elapsed":8571,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"}},"outputId":"b0398807-76b4-48ca-f2e5-d5ad9a9b32ac"},"source":["!pip install tokenizers\n","from tokenizers import ByteLevelBPETokenizer\n","from tokenizers.processors import BertProcessing\n","\n","def train_tokenizer(input_path, output_path, vocab_size=10000):\n","    tokenizer = ByteLevelBPETokenizer()\n","    tokenizer.train(files=[input_path], vocab_size=vocab_size, special_tokens=[\"[PAD]\", \"<s>\", \"</s>\", \"<unk>\"])\n","    tokenizer._tokenizer.post_processor = BertProcessing(\n","        (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n","        (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n","    )\n","    tokenizer.save_model(output_path)\n","    return tokenizer\n","\n","def get_tokenizer(path):\n","    tokenizer = ByteLevelBPETokenizer(path + 'vocab.json', path + 'merges.txt')\n","    tokenizer._tokenizer.post_processor = BertProcessing(\n","        (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n","        (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n","    )\n","    return tokenizer"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.10.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NfMwC8wCnaUn","executionInfo":{"status":"ok","timestamp":1620312226066,"user_tz":-120,"elapsed":9007,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"}},"outputId":"68e30acd-c710-4964-9a3b-ab1e3eeb1c88"},"source":["import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","import re\n","\n","def clean_line(s):\n","    s = s.lower()\n","    s = re.sub(r\"\\.{3}\", r\".\", s)\n","    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n","    return s\n","\n","def tokenize_line(line):\n","    tokens = word_tokenize(line)\n","    tokens_text = ' '.join(tokens)\n","    return tokens_text"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YZdQN1EuUiO6","executionInfo":{"status":"ok","timestamp":1620312226067,"user_tz":-120,"elapsed":9006,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"}}},"source":["import torch\n","import random\n","\n","MAX_LENGTH = 30\n","decoding_strategy='multinomial'\n","\n","def decode(logits, tokenizer, decoding_strategy='multinomial', k=3, temp=0.4):\n","    tokenizer.decode(logits.topk(10)[1][0].numpy())\n","    if decoding_strategy=='top1':\n","        target = logits.max(1)[1]\n","    elif decoding_strategy=='topk':\n","        target = logits.topk(k)[1][0][random.randint(0, k-1)].unsqueeze(-1)\n","    else:\n","        target = torch.multinomial(logits.squeeze().div(temp).exp().cpu(), 1)\n","    return target\n","\n","def evaluate(sentence, model, tokenizer, decoding_strategy='multinomial', k=3, temp=0.4):\n","    sentence = clean_line(sentence)\n","    sentence = tokenize_line(sentence)\n","    with torch.no_grad():\n","        target = torch.Tensor([tokenizer.token_to_id('<s>')]).long()\n","        output_sentence = []\n","        encoder_outputs, hidden = model.encoder(torch.Tensor(tokenizer.encode(sentence).ids).long().unsqueeze(-1))\n","        attentions = torch.zeros(MAX_LENGTH, 1, len(tokenizer.encode(sentence).ids)).to(device)\n","        for i in range(MAX_LENGTH):\n","            # first input to the decoder is the <sos> token\n","            output, hidden, attention = model.decoder(target, hidden, encoder_outputs)\n","            attentions[i] = attention\n","            target = decode(output, tokenizer, decoding_strategy, k, temp)\n","            if target.numpy() == tokenizer.token_to_id('</s>'):\n","                return sentence, tokenizer.decode(output_sentence), attentions[:i+1]\n","            else:\n","                output_sentence.append(target.numpy()[0])\n","    return sentence, tokenizer.decode(output_sentence), attentions"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wvijPasdZze-","executionInfo":{"status":"ok","timestamp":1620312228499,"user_tz":-120,"elapsed":11433,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"}},"outputId":"665dbd2e-a959-4afe-9030-90db0689398e"},"source":["INPUT_DIM = 10000\n","OUTPUT_DIM = 10000\n","ENC_EMB_DIM = 512\n","DEC_EMB_DIM = 512\n","ENC_HID_DIM = 1024\n","DEC_HID_DIM = 1024\n","ATTN_DIM = 1024\n","ENC_DROPOUT = 0.2\n","DEC_DROPOUT = 0.2\n","#Load model\n","device = 'cpu'\n","enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n","attn = Attention(ENC_HID_DIM, DEC_HID_DIM, ATTN_DIM)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n","model_en = Seq2Seq(enc, dec, device).to(device)\n","model_en.load_state_dict(torch.load('../model/en/model.pt', map_location=device))\n","tokenizer_en = get_tokenizer('../model/en/')\n","model_en.eval()\n","\n","INPUT_DIM_EU = 10000\n","OUTPUT_DIM_EU = 10000\n","ENC_EMB_DIM_EU = 256\n","DEC_EMB_DIM_EU = 256\n","ENC_HID_DIM_EU = 512\n","DEC_HID_DIM_EU = 512\n","ATTN_DIM_EU = 64\n","ENC_DROPOUT_EU = 0.5\n","DEC_DROPOUT_EU = 0.5\n","#Load model\n","device = 'cpu'\n","enc = Encoder(INPUT_DIM_EU, ENC_EMB_DIM_EU, ENC_HID_DIM_EU, DEC_HID_DIM_EU, ENC_DROPOUT_EU)\n","attn = Attention(ENC_HID_DIM_EU, DEC_HID_DIM_EU, ATTN_DIM_EU)\n","dec = Decoder(OUTPUT_DIM_EU, DEC_EMB_DIM_EU, ENC_HID_DIM_EU, DEC_HID_DIM_EU, DEC_DROPOUT_EU, attn)\n","model_eu = Seq2Seq(enc, dec, device).to(device)\n","model_eu.load_state_dict(torch.load('../model/eu/model.pt', map_location=device))\n","tokenizer_eu = get_tokenizer('../model/eu/')\n","model_eu.eval()"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Seq2Seq(\n","  (encoder): Encoder(\n","    (embedding): Embedding(10000, 256)\n","    (rnn): GRU(256, 512, bidirectional=True)\n","    (fc): Linear(in_features=1024, out_features=512, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): Decoder(\n","    (attention): Attention(\n","      (attn): Linear(in_features=1536, out_features=64, bias=True)\n","    )\n","    (embedding): Embedding(10000, 256)\n","    (rnn): GRU(1280, 512)\n","    (out): Linear(in_features=1792, out_features=10000, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"6Qot1kYVipVk","executionInfo":{"status":"ok","timestamp":1620312228500,"user_tz":-120,"elapsed":11433,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"}}},"source":["from telegram import InlineKeyboardButton, InlineKeyboardMarkup, Update"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sSssmU4B2RvV"},"source":["```\n","/en - change language to english\n","/eu - change language to euskera\n","/top1 - change decoding to top1\n","/topk - change decoding to topk\n","/multinomial - change decoding to multinomial\n","/language - check current language\n","/setlanguage - choose a language\n","/decoding - check current decoding strategy\n","/setdecoding - choose a decoding strategy\n","/help - show list of commands\n","/settings - show settings\n","```"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TZxcuEq1MiiT","executionInfo":{"status":"ok","timestamp":1620314168201,"user_tz":-120,"elapsed":1951129,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"}},"outputId":"57f11051-d65a-421c-8e49-dfb77509c4fb"},"source":["import logging\n","\n","from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackQueryHandler, ConversationHandler ,CallbackContext\n","#language\n","lang='en'\n","# Enable logging\n","logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n","                    level=logging.INFO)\n","\n","logger = logging.getLogger(__name__)\n","\n","\n","# Define a few command handlers. These usually take the two arguments update and\n","# context. Error handlers also receive the raised TelegramError object in error.\n","def start(update, context):\n","    \"\"\"Send a message when the command /start is issued.\"\"\"\n","    if lang == 'eu':\n","        update.message.reply_text('Kaixo! Dialbot naiz. Komandoen zerrenda ikusteko /help erabili🧐.')\n","    else:\n","        update.message.reply_text('Hi! I\\'m dialbot. Use /help to see a list of all comands🧐.')\n","\n","\n","def language_changed(update, context):\n","    if lang == 'eu':\n","        update.message.reply_text('Hizkuntza aldatu da.')\n","    else:\n","        update.message.reply_text('Language changed.')\n","\n","def decoding_changed(update, context):\n","    if lang == 'eu':\n","        update.message.reply_text(f\"Dekodeketa estrategia aldatu da: {decoding_strategy}\")\n","    else:\n","        update.message.reply_text(f\"Decoding strategy changed: {decoding_strategy}\")\n","\n","def help(update, context):\n","    \"\"\"Send a message when the command /help is issued.\"\"\"\n","    if lang == 'eu':\n","        text = \"\"\"\n","*Hizkuntza*\n","/en \\- hizkuntza ingelesera aldatu\n","/eu \\- hizkuntza euskerara aldatu\n","/language \\- hizkuntza egiaztatu\n","/setlanguage \\- hizkuntza aukeratu \\n\n","*Dekodeketa estrategia*\n","/multinomial \\- dekodeketa estrategia aldatu multionomial\\-era\n","/top1 \\- dekodeketa estrategia aldatu top1\\-era\n","/topk \\- dekodeketa estrategia aldatu topk\\-ra\n","/decoding \\- aukeratutako dekodeketa estrategia ikusi \n","/setdecoding \\- aukeratu dekodeketa estrategia \\n\n","*Ezarpen nagusiak*\n","/settings \\- ezarpenak ikusi\n","/help \\- komandoen lista ikusi\"\"\"\n","    else:\n","        text = \"\"\"\n","*Language*\n","/en \\- change language to English\n","/eu \\- change language to Euskera \n","/language \\- check current language\n","/setlanguage \\- choose a language \\n\n","*Decoding strategy*\n","/multinomial \\- change decoding to multinomial\n","/top1 \\- change decoding to top1\n","/topk \\- change decoding to topk\n","/decoding \\- check current decoding strategy\n","/setdecoding \\- choose a decoding strategy \\n\n","*General settings*\n","/settings \\- show settings\n","/help \\- show list of commands\"\"\"\n","    update.message.reply_text(text, parse_mode='MarkdownV2')\n","\n","def eu(update, context):\n","    \"\"\"Change language to Euskera.\"\"\"\n","    global lang\n","    lang = 'eu'\n","    language_changed(update,context)\n","\n","def en(update, context):\n","    \"\"\"Change language to English\"\"\"\n","    global lang\n","    lang = 'en'\n","    language_changed(update, context)\n","\n","def top1(update, context):\n","    \"\"\"Change language to Euskera.\"\"\"\n","    global decoding_strategy\n","    decoding_strategy = 'top1'\n","    decoding_changed(update,context)\n","\n","def topk(update, context):\n","    \"\"\"Change language to English\"\"\"\n","    global decoding_strategy\n","    decoding_strategy = 'topk'\n","    decoding_changed(update, context)\n","\n","def multinomial(update, context):\n","    \"\"\"Change language to English\"\"\"\n","    global decoding_strategy\n","    decoding_strategy = 'multinomial'\n","    decoding_changed(update, context)\n","\n","def language(update, context):\n","    \"\"\"Reply with current language\"\"\"\n","    if lang == 'eu':\n","        update.message.reply_text('Euskara')\n","    else:\n","        update.message.reply_text('English')\n","\n","def settings(update, context):\n","    \"\"\"Reply with current language\"\"\"\n","    if lang == 'eu':\n","        text = f\"\"\" \n","*Ezarpenak*\n","Hizkuntza: {lang}\n","Deskodeketa estrategia: {decoding_strategy}\"\"\"\n","    else:\n","        text = f\"\"\" \n","*Settings*\n","Language: {lang}\n","Decoding strategy: {decoding_strategy}\"\"\"\n","    update.message.reply_text(text, parse_mode='MarkdownV2')\n","\n","def set_language(update, context):\n","    \"\"\"Set language to English or Euskara\"\"\"\n","    bot = context.bot\n","    languages = ['English', 'Euskara']\n","    callback = ['en', 'eu']\n","    button_list = []\n","    if lang == 'eu':\n","        senc='Aukeratu hizkuntza'\n","    else:\n","        senc='Choose a language'\n","    for i, each in enumerate(languages):\n","        button_list.append(InlineKeyboardButton(each, callback_data=callback[i]))\n","    reply_markup = InlineKeyboardMarkup(build_menu(button_list, n_cols=1))\n","    bot.send_message(chat_id=update.message.chat_id, text=senc, reply_markup=reply_markup)\n","\n","def decoding(update, context):\n","    \"\"\"Reply with current decoding strategy\"\"\"\n","    update.message.reply_text(decoding_strategy)\n","    \n","def set_decoding(update, context):\n","    \"\"\"Set decoding strategy to top1, topk or multinomial\"\"\"\n","    bot = context.bot\n","    list_of_strategies = ['top1', 'topk', 'multinomial']\n","    button_list = []\n","    if lang == 'eu':\n","        senc='Aukeratu deskodeketa estrategia'\n","    else:\n","        senc='Choose a decoding strategy'\n","    for each in list_of_strategies:\n","        button_list.append(InlineKeyboardButton(each, callback_data = each))\n","    reply_markup = InlineKeyboardMarkup(build_menu(button_list, n_cols=1))\n","    bot.send_message(chat_id=update.message.chat_id, text=senc, reply_markup=reply_markup)\n","\n","def build_menu(buttons, n_cols, header_buttons=None, footer_buttons=None):\n","    menu = [buttons[i:i + n_cols] for i in range(0, len(buttons), n_cols)]\n","    if header_buttons:\n","        menu.insert(0, header_buttons)\n","    if footer_buttons:\n","        menu.append(footer_buttons)\n","    return menu\n","\n","# Callbacks\n","\n","def decoding_callback(update, context):\n","    global decoding_strategy\n","    decoding_strategy = update.callback_query.data\n","    id = update.callback_query.message.chat.id\n","    if lang == 'eu':\n","        context.bot.send_message(chat_id=id, text=f\"Dekodeketa estrategia aldatu da: {decoding_strategy}\")\n","    else:\n","        context.bot.send_message(chat_id=id, text=f\"Decoding strategy changed: {decoding_strategy}\")\n","\n","def language_callback(update, context):\n","    global lang\n","    id = update.callback_query.message.chat.id\n","    lang = update.callback_query.data\n","    if lang == 'eu':\n","        context.bot.send_message(chat_id=id, text=\"Hizkuntza aldatu da\")\n","    else:\n","        context.bot.send_message(chat_id=id, text=\"Language changed\")\n","    \n","# Messages\n","\n","def answer(update, context):\n","    \"\"\"Answer to the user message.\"\"\"\n","    global model_en\n","    global model_eu\n","    global tokenizer_en\n","    global tokenizer_eu\n","    global decoding_strategy\n","    input = update.message.text\n","    if lang == 'eu':\n","        sentence, output, attention = evaluate(input, model_eu, tokenizer_eu, decoding_strategy)\n","    else:\n","        sentence, output, attention = evaluate(input, model_en, tokenizer_en, decoding_strategy)\n","    update.message.reply_text(output.capitalize())\n","\n","def unknown(update, context):\n","    if lang == 'eu':\n","        text = \"Barkatu, komando hori ez dut ezagutzen. Komandoen zerrenda ikusteko /help erabili.\"\n","    else:\n","        text = \"Sorry, I didn't understand that command. Use /help to see a list of all comands.\"\n","    update.message.reply_text(text)\n","\n","# Errors\n","\n","def error(update, context):\n","    \"\"\"Log Errors caused by Updates.\"\"\"\n","    logger.warning('Update \"%s\" caused error \"%s\"', update, context.error)\n","\n","def main():\n","    \"\"\"Start the bot.\"\"\"\n","    # Create the Updater and pass it your bot's token.\n","    # Make sure to set use_context=True to use the new context based callbacks\n","    # Post version 12 this will no longer be necessary\n","    updater = Updater(TOKEN, use_context=True)\n","\n","    # Get the dispatcher to register handlers\n","    dp = updater.dispatcher\n","\n","    # on different commands - answer in Telegram\n","    dp.add_handler(CommandHandler(\"start\", start))\n","    dp.add_handler(CommandHandler(\"help\", help))\n","    dp.add_handler(CommandHandler(\"eu\", eu))\n","    dp.add_handler(CommandHandler(\"en\", en))\n","    dp.add_handler(CommandHandler(\"top1\", top1))\n","    dp.add_handler(CommandHandler(\"topk\", topk))\n","    dp.add_handler(CommandHandler(\"multinomial\", multinomial))\n","    dp.add_handler(CommandHandler('settings', settings))\n","    dp.add_handler(CommandHandler('language', language))\n","    dp.add_handler(CommandHandler('setlanguage', set_language))\n","    dp.add_handler(CommandHandler('decoding', decoding))\n","    dp.add_handler(CommandHandler('setdecoding', set_decoding))\n","    # callback handlers\n","    dp.add_handler(CallbackQueryHandler(decoding_callback, pattern=\"^top1|topk|multinomial$\"))\n","    dp.add_handler(CallbackQueryHandler(language_callback, pattern=\"^en|eu$\"))\n","    # on noncommand message\n","    dp.add_handler(MessageHandler(Filters.text & (~Filters.command), answer))\n","    # on unknown commmand\n","    dp.add_handler(MessageHandler(Filters.command, unknown))\n","\n","    # log all errors\n","    dp.add_error_handler(error)\n","\n","    # Start the Bot\n","    updater.start_polling()\n","\n","\n","    # Run the bot until you press Ctrl-C or the process receives SIGINT,\n","    # SIGTERM or SIGABRT. This should be used most of the time, since\n","    # start_polling() is non-blocking and will stop the bot gracefully.\n","    updater.idle()\n","\n","\n","if __name__ == '__main__':\n","    main()"],"execution_count":17,"outputs":[{"output_type":"stream","text":["2021-05-06 14:43:48,545 - apscheduler.scheduler - INFO - Scheduler started\n","2021-05-06 15:16:03,258 - telegram.ext.updater - INFO - Received signal 2 (SIGINT), stopping...\n","2021-05-06 15:16:03,266 - apscheduler.scheduler - INFO - Scheduler has been shut down\n"],"name":"stderr"}]}]}