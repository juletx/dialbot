{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1750,"status":"ok","timestamp":1619907963659,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"},"user_tz":-120},"id":"cG8tH4YcSMap","outputId":"3c5d7eb3-4b3a-4029-ad91-ed87be599420"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1745,"status":"ok","timestamp":1619907963661,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"},"user_tz":-120},"id":"KxyVJIpGCpup","outputId":"3404d75e-6466-412b-df3d-4ad2d1e6536d"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Errno 2] No such file or directory: '/content/drive/MyDrive/Ingeniaritza Informatikoa/4. Maila/2. Lauhilekoa/HP/Lana/dialbot/notebook'\n","/content\n"]}],"source":["%cd \"/content/drive/MyDrive/Ingeniaritza Informatikoa/4. Maila/2. Lauhilekoa/HP/Lana/dialbot/notebook\""]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1738,"status":"ok","timestamp":1619907963661,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"},"user_tz":-120},"id":"Zu9bpmbLSUI2","outputId":"9221ca08-f9ce-411c-bfb1-224b43a8cb11"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/13R7fsJaBA2ra3u5WI5-hbHRUYUzCn976/dialbot/notebook\n"]}],"source":["%cd \"/content/drive/MyDrive/dialbot/notebook\""]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5055,"status":"ok","timestamp":1619907966984,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"},"user_tz":-120},"id":"3iuwTfhYNb71","outputId":"7bc5bda1-c8e4-479d-8c45-b56e4ddea6e6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: python-telegram-bot in /usr/local/lib/python3.7/dist-packages (13.5)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (2020.12.5)\n","Requirement already satisfied: pytz\u003e=2018.6 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (2018.9)\n","Requirement already satisfied: tornado\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (5.1.1)\n","Requirement already satisfied: APScheduler==3.6.3 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (3.6.3)\n","Requirement already satisfied: setuptools\u003e=0.7 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3-\u003epython-telegram-bot) (56.0.0)\n","Requirement already satisfied: tzlocal\u003e=1.2 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3-\u003epython-telegram-bot) (1.5.1)\n","Requirement already satisfied: six\u003e=1.4.0 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3-\u003epython-telegram-bot) (1.15.0)\n"]}],"source":["pip install python-telegram-bot"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5054,"status":"ok","timestamp":1619907966984,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"},"user_tz":-120},"id":"UlYR_2YFk2mW"},"outputs":[],"source":["save_path='token.txt'"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":5053,"status":"ok","timestamp":1619907966985,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"},"user_tz":-120},"id":"hdYO0XSEkr6N"},"outputs":[],"source":["with open(save_path) as creds:\n","    for i, line in enumerate(creds):\n","        if i == 1:\n","            TOKEN = line.replace(\"token=\", \"\").replace(\"\\n\", \"\")"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5463,"status":"ok","timestamp":1619907967397,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"},"user_tz":-120},"id":"UPQbW9JCCmhU"},"outputs":[],"source":["import random\n","from typing import Tuple\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch import Tensor\n","\n","\n","class Encoder(nn.Module):\n","    def __init__(self,\n","                 input_dim: int,\n","                 emb_dim: int,\n","                 enc_hid_dim: int,\n","                 dec_hid_dim: int,\n","                 dropout: float):\n","        super().__init__()\n","\n","        self.input_dim = input_dim\n","        self.emb_dim = emb_dim\n","        self.enc_hid_dim = enc_hid_dim\n","        self.dec_hid_dim = dec_hid_dim\n","        self.dropout = dropout\n","\n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","\n","        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n","\n","        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self,\n","                src: Tensor) -\u003e Tuple[Tensor]:\n","\n","        embedded = self.dropout(self.embedding(src))\n","\n","        outputs, hidden = self.rnn(embedded)\n","\n","        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n","\n","        return outputs, hidden"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5463,"status":"ok","timestamp":1619907967398,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"},"user_tz":-120},"id":"OrlmOMpTCosz"},"outputs":[],"source":["class Attention(nn.Module):\n","    def __init__(self,\n","                 enc_hid_dim: int,\n","                 dec_hid_dim: int,\n","                 attn_dim: int):\n","        super().__init__()\n","\n","        self.enc_hid_dim = enc_hid_dim\n","        self.dec_hid_dim = dec_hid_dim\n","\n","        self.attn_in = (enc_hid_dim * 2) + dec_hid_dim\n","\n","        self.attn = nn.Linear(self.attn_in, attn_dim)\n","\n","    def forward(self,\n","                decoder_hidden: Tensor,\n","                encoder_outputs: Tensor) -\u003e Tensor:\n","\n","        src_len = encoder_outputs.shape[0]\n","\n","        repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n","\n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","\n","        energy = torch.tanh(self.attn(torch.cat((\n","            repeated_decoder_hidden,\n","            encoder_outputs),\n","            dim = 2)))\n","\n","        attention = torch.sum(energy, dim=2)\n","\n","        return F.softmax(attention, dim=1)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5462,"status":"ok","timestamp":1619907967398,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"},"user_tz":-120},"id":"pbLkV14gCsP0"},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self,\n","                 output_dim: int,\n","                 emb_dim: int,\n","                 enc_hid_dim: int,\n","                 dec_hid_dim: int,\n","                 dropout: int,\n","                 attention: nn.Module):\n","        super().__init__()\n","\n","        self.emb_dim = emb_dim\n","        self.enc_hid_dim = enc_hid_dim\n","        self.dec_hid_dim = dec_hid_dim\n","        self.output_dim = output_dim\n","        self.dropout = dropout\n","        self.attention = attention\n","\n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","\n","        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n","\n","        self.out = nn.Linear(self.attention.attn_in + emb_dim, output_dim)\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","\n","    def _weighted_encoder_rep(self,\n","                              decoder_hidden: Tensor,\n","                              encoder_outputs: Tensor) -\u003e Tensor:\n","\n","        a = self.attention(decoder_hidden, encoder_outputs)\n","\n","        a = a.unsqueeze(1)\n","\n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","\n","        weighted_encoder_rep = torch.bmm(a, encoder_outputs)\n","\n","        weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2)\n","\n","        return weighted_encoder_rep, a\n","\n","\n","    def forward(self,\n","                input: Tensor,\n","                decoder_hidden: Tensor,\n","                encoder_outputs: Tensor) -\u003e Tuple[Tensor]:\n","\n","        input = input.unsqueeze(0)\n","\n","        embedded = self.dropout(self.embedding(input))\n","\n","        weighted_encoder_rep, a = self._weighted_encoder_rep(decoder_hidden,\n","                                                          encoder_outputs)\n","\n","        rnn_input = torch.cat((embedded, weighted_encoder_rep), dim = 2)\n","\n","        output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0))\n","\n","        embedded = embedded.squeeze(0)\n","        output = output.squeeze(0)\n","        weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\n","\n","        output = self.out(torch.cat((output,\n","                                     weighted_encoder_rep,\n","                                     embedded), dim = 1))\n","\n","        return output, decoder_hidden.squeeze(0), a.squeeze(1)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5460,"status":"ok","timestamp":1619907967398,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"},"user_tz":-120},"id":"X_-VQxpZzSao"},"outputs":[],"source":["class Seq2Seq(nn.Module):\n","    def __init__(self,\n","                 encoder: nn.Module,\n","                 decoder: nn.Module,\n","                 device: torch.device):\n","        super().__init__()\n","\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","\n","    def forward(self,\n","                src: Tensor,\n","                trg: Tensor,\n","                teacher_forcing_ratio: float = 0.5) -\u003e Tensor:\n","\n","        batch_size = src.shape[1]\n","        max_len = trg.shape[0]\n","        trg_vocab_size = self.decoder.output_dim\n","\n","        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n","\n","        encoder_outputs, hidden = self.encoder(src)\n","\n","        # first input to the decoder is the \u003csos\u003e token\n","        output = trg[0,:]\n","        for t in range(1, max_len):\n","            output, hidden, _ = self.decoder(output, hidden, encoder_outputs)\n","            outputs[t] = output\n","            teacher_force = random.random() \u003c teacher_forcing_ratio\n","            top1 = output.max(1)[1]\n","            output = (trg[t] if teacher_force else top1)\n","\n","        return outputs"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8968,"status":"ok","timestamp":1619907970911,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"},"user_tz":-120},"id":"AJ35JZRnTWU2","outputId":"9a674b10-33f5-4feb-81a8-3c1133320985"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.10.2)\n"]}],"source":["!pip install tokenizers\n","from tokenizers import ByteLevelBPETokenizer\n","from tokenizers.processors import BertProcessing\n","\n","def train_tokenizer(input_path, output_path, vocab_size=10000):\n","    tokenizer = ByteLevelBPETokenizer()\n","    tokenizer.train(files=[input_path], vocab_size=vocab_size, special_tokens=[\"[PAD]\", \"\u003cs\u003e\", \"\u003c/s\u003e\", \"\u003cunk\u003e\"])\n","    tokenizer._tokenizer.post_processor = BertProcessing(\n","        (\"\u003c/s\u003e\", tokenizer.token_to_id(\"\u003c/s\u003e\")),\n","        (\"\u003cs\u003e\", tokenizer.token_to_id(\"\u003cs\u003e\")),\n","    )\n","    tokenizer.save_model(output_path)\n","    return tokenizer\n","\n","def get_tokenizer(path):\n","    tokenizer = ByteLevelBPETokenizer(path + 'vocab.json', path + 'merges.txt')\n","    tokenizer._tokenizer.post_processor = BertProcessing(\n","        (\"\u003c/s\u003e\", tokenizer.token_to_id(\"\u003c/s\u003e\")),\n","        (\"\u003cs\u003e\", tokenizer.token_to_id(\"\u003cs\u003e\")),\n","    )\n","    return tokenizer"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9703,"status":"ok","timestamp":1619907971650,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"},"user_tz":-120},"id":"NfMwC8wCnaUn","outputId":"0845363a-aa36-4d17-9246-ee68c2363f5f"},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","import re\n","\n","def clean_line(s):\n","    s = s.lower()\n","    s = re.sub(r\"\\.{3}\", r\".\", s)\n","    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n","    return s\n","\n","def tokenize_line(line):\n","    tokens = word_tokenize(line)\n","    tokens_text = ' '.join(tokens)\n","    return tokens_text"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":9703,"status":"ok","timestamp":1619907971651,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"},"user_tz":-120},"id":"YZdQN1EuUiO6"},"outputs":[],"source":["import torch\n","import random\n","\n","MAX_LENGTH = 30\n","decoding_strategy='multinomial'\n","\n","def decode(logits, tokenizer, decoding_strategy='multinomial', k=3, temp=0.4):\n","    tokenizer.decode(logits.topk(10)[1][0].numpy())\n","    if decoding_strategy=='top1':\n","        target = logits.max(1)[1]\n","    elif decoding_strategy=='topk':\n","        target = logits.topk(k)[1][0][random.randint(0, k-1)].unsqueeze(-1)\n","    else:\n","        target = torch.multinomial(logits.squeeze().div(temp).exp().cpu(), 1)\n","    return target\n","\n","def evaluate(sentence, model, tokenizer, decoding_strategy='multinomial', k=3, temp=0.4):\n","    sentence = clean_line(sentence)\n","    sentence = tokenize_line(sentence)\n","    with torch.no_grad():\n","        target = torch.Tensor([tokenizer.token_to_id('\u003cs\u003e')]).long()\n","        output_sentence = []\n","        encoder_outputs, hidden = model.encoder(torch.Tensor(tokenizer.encode(sentence).ids).long().unsqueeze(-1))\n","        attentions = torch.zeros(MAX_LENGTH, 1, len(tokenizer.encode(sentence).ids)).to(device)\n","        for i in range(MAX_LENGTH):\n","            # first input to the decoder is the \u003csos\u003e token\n","            output, hidden, attention = model.decoder(target, hidden, encoder_outputs)\n","            attentions[i] = attention\n","            target = decode(output, tokenizer, decoding_strategy, k, temp)\n","            if target.numpy() == tokenizer.token_to_id('\u003c/s\u003e'):\n","                return sentence, tokenizer.decode(output_sentence), attentions[:i+1]\n","            else:\n","                output_sentence.append(target.numpy()[0])\n","    return sentence, tokenizer.decode(output_sentence), attentions"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11805,"status":"ok","timestamp":1619907973758,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"},"user_tz":-120},"id":"wvijPasdZze-","outputId":"a57f4b4a-6c01-489c-b5b9-369fd48a0faf"},"outputs":[{"data":{"text/plain":["Seq2Seq(\n","  (encoder): Encoder(\n","    (embedding): Embedding(10000, 256)\n","    (rnn): GRU(256, 512, bidirectional=True)\n","    (fc): Linear(in_features=1024, out_features=512, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): Decoder(\n","    (attention): Attention(\n","      (attn): Linear(in_features=1536, out_features=64, bias=True)\n","    )\n","    (embedding): Embedding(10000, 256)\n","    (rnn): GRU(1280, 512)\n","    (out): Linear(in_features=1792, out_features=10000, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")"]},"execution_count":14,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["INPUT_DIM = 10000\n","OUTPUT_DIM = 10000\n","ENC_EMB_DIM = 512\n","DEC_EMB_DIM = 512\n","ENC_HID_DIM = 1024\n","DEC_HID_DIM = 1024\n","ATTN_DIM = 1024\n","ENC_DROPOUT = 0.2\n","DEC_DROPOUT = 0.2\n","#Load model\n","device = 'cpu'\n","enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n","attn = Attention(ENC_HID_DIM, DEC_HID_DIM, ATTN_DIM)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n","model_en = Seq2Seq(enc, dec, device).to(device)\n","model_en.load_state_dict(torch.load('../model/en/model.pt', map_location=device))\n","tokenizer_en = get_tokenizer('../model/en/')\n","model_en.eval()\n","\n","INPUT_DIM_EU = 10000\n","OUTPUT_DIM_EU = 10000\n","ENC_EMB_DIM_EU = 256\n","DEC_EMB_DIM_EU = 256\n","ENC_HID_DIM_EU = 512\n","DEC_HID_DIM_EU = 512\n","ATTN_DIM_EU = 64\n","ENC_DROPOUT_EU = 0.5\n","DEC_DROPOUT_EU = 0.5\n","#Load model\n","device = 'cpu'\n","enc = Encoder(INPUT_DIM_EU, ENC_EMB_DIM_EU, ENC_HID_DIM_EU, DEC_HID_DIM_EU, ENC_DROPOUT_EU)\n","attn = Attention(ENC_HID_DIM_EU, DEC_HID_DIM_EU, ATTN_DIM_EU)\n","dec = Decoder(OUTPUT_DIM_EU, DEC_EMB_DIM_EU, ENC_HID_DIM_EU, DEC_HID_DIM_EU, DEC_DROPOUT_EU, attn)\n","model_eu = Seq2Seq(enc, dec, device).to(device)\n","model_eu.load_state_dict(torch.load('../model/eu/model.pt', map_location=device))\n","tokenizer_eu = get_tokenizer('../model/eu/')\n","model_eu.eval()"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":11805,"status":"ok","timestamp":1619907973759,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"},"user_tz":-120},"id":"6Qot1kYVipVk"},"outputs":[],"source":["from telegram import InlineKeyboardButton, InlineKeyboardMarkup, Update"]},{"cell_type":"markdown","metadata":{"id":"sSssmU4B2RvV"},"source":["```\n","/en - change language to english\n","/eu - change language to euskera\n","/language - check current language\n","/setlanguage - choose a language\n","/decoding - check current decoding strategy\n","/setdecoding - choose a decoding strategy\n","/help - show list of commands\n","/settings - show settings\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"TZxcuEq1MiiT"},"outputs":[{"name":"stderr","output_type":"stream","text":["2021-05-01 22:38:32,906 - apscheduler.scheduler - INFO - Scheduler started\n","2021-05-02 00:32:04,260 - telegram.ext.updater - INFO - Received signal 2 (SIGINT), stopping...\n","2021-05-02 00:32:04,268 - apscheduler.scheduler - INFO - Scheduler has been shut down\n"]}],"source":["import logging\n","\n","from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackQueryHandler, ConversationHandler ,CallbackContext\n","#language\n","lang='en'\n","# Enable logging\n","logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n","                    level=logging.INFO)\n","\n","logger = logging.getLogger(__name__)\n","\n","\n","# Define a few command handlers. These usually take the two arguments update and\n","# context. Error handlers also receive the raised TelegramError object in error.\n","def start(update, context):\n","    \"\"\"Send a message when the command /start is issued.\"\"\"\n","    if lang == 'eu':\n","        update.message.reply_text('Kaixo! Dialbot naiz. Komandoen zerrenda ikusteko /help erabili🧐.')\n","    else:\n","        update.message.reply_text('Hi! I\\'m dialbot. Use /help to see a list of all comands🧐.')\n","\n","\n","def language_changed(update, context):\n","    if lang == 'eu':\n","        update.message.reply_text('Hizkuntza aldatu da.')\n","    else:\n","        update.message.reply_text('Language changed.')\n","\n","def help(update, context):\n","    \"\"\"Send a message when the command /help is issued.\"\"\"\n","    if lang == 'eu':\n","        text = \"\"\"\n","*Hizkuntza*\n","/en \\- hizkuntza ingelesera aldatu\n","/eu \\- hizkuntza euskerara aldatu\n","/language \\- hizkuntza egiaztatu\n","/setlanguage \\- hizkuntza aukeratu \\n\n","*Dekodeketa estrategia*\n","/decoding \\- aukeratutako dekodeketa estrategia ikusi \n","/setdecoding \\- aukeratu dekodeketa estrategia \\n\n","*Ezarpen nagusiak*\n","/settings \\- ezarpenak ikusi\n","/help \\- komandoen lista ikusi\"\"\"\n","    else:\n","        text = \"\"\"\n","*Language*\n","/en \\- change language to English\n","/eu \\- change language to Euskera \n","/language \\- check current language\n","/setlanguage \\- choose a language \\n\n","*Decoding strategy*\n","/decoding \\- check current decoding strategy\n","/setdecoding \\- choose a decoding strategy \\n\n","*General settings*\n","/settings \\-show settings\n","/help \\-show list of commands\"\"\"\n","    update.message.reply_text(text, parse_mode='MarkdownV2')\n","\n","def eu(update, context):\n","    \"\"\"Change language to Euskera.\"\"\"\n","    global lang\n","    lang = 'eu'\n","    language_changed(update,context)\n","\n","def en(update, context):\n","    \"\"\"Change language to English\"\"\"\n","    global lang\n","    lang = 'en'\n","    language_changed(update, context)\n","\n","def language(update, context):\n","    \"\"\"Reply with current language\"\"\"\n","    if lang == 'eu':\n","        update.message.reply_text('Euskara')\n","    else:\n","        update.message.reply_text('English')\n","\n","def settings(update, context):\n","    \"\"\"Reply with current language\"\"\"\n","    if lang == 'eu':\n","        text = f\"\"\" \n","*Ezarpenak*\n","Hizkuntza: {lang}\n","Deskodeketa estrategia: {decoding_strategy}\"\"\"\n","    else:\n","        text = f\"\"\" \n","*Settings*\n","Language: {lang}\n","Decoding strategy: {decoding_strategy}\"\"\"\n","    update.message.reply_text(text, parse_mode='MarkdownV2')\n","\n","def set_language(update, context):\n","    \"\"\"Set language to English or Euskara\"\"\"\n","    bot = context.bot\n","    languages = ['English', 'Euskara']\n","    callback = ['en', 'eu']\n","    button_list = []\n","    if lang == 'eu':\n","        senc='Aukeratu hizkuntza'\n","    else:\n","        senc='Choose a language'\n","    for i, each in enumerate(languages):\n","        button_list.append(InlineKeyboardButton(each, callback_data=callback[i]))\n","    reply_markup = InlineKeyboardMarkup(build_menu(button_list, n_cols=1))\n","    bot.send_message(chat_id=update.message.chat_id, text=senc, reply_markup=reply_markup)\n","\n","def decoding(update, context):\n","    \"\"\"Reply with current decoding strategy\"\"\"\n","    update.message.reply_text(decoding_strategy)\n","    \n","def set_decoding(update, context):\n","    \"\"\"Set decoding strategy to top1, topk or multinomial\"\"\"\n","    bot = context.bot\n","    list_of_strategies = ['top1', 'topk', 'multinomial']\n","    button_list = []\n","    if lang == 'eu':\n","        senc='Aukeratu deskodeketa estrategia'\n","    else:\n","        senc='Choose a decoding strategy'\n","    for each in list_of_strategies:\n","        button_list.append(InlineKeyboardButton(each, callback_data = each))\n","    reply_markup = InlineKeyboardMarkup(build_menu(button_list, n_cols=1))\n","    bot.send_message(chat_id=update.message.chat_id, text=senc, reply_markup=reply_markup)\n","\n","def build_menu(buttons, n_cols, header_buttons=None, footer_buttons=None):\n","    menu = [buttons[i:i + n_cols] for i in range(0, len(buttons), n_cols)]\n","    if header_buttons:\n","        menu.insert(0, header_buttons)\n","    if footer_buttons:\n","        menu.append(footer_buttons)\n","    return menu\n","\n","# Callbacks\n","\n","def decoding_callback(update, context):\n","    global decoding_strategy\n","    decoding_strategy = update.callback_query.data\n","    id = update.callback_query.message.chat.id\n","    if lang == 'eu':\n","        context.bot.send_message(chat_id=id, text=f\"Dekodeketa estrategia aldatu da: {decoding_strategy}\")\n","    else:\n","        context.bot.send_message(chat_id=id, text=f\"Decoding strategy changed: {decoding_strategy}\")\n","def language_callback(update, context):\n","    global lang\n","    id = update.callback_query.message.chat.id\n","    lang = update.callback_query.data\n","    if lang == 'eu':\n","        context.bot.send_message(chat_id=id, text=\"Hizkuntza aldatu da\")\n","    else:\n","        context.bot.send_message(chat_id=id, text=\"Language changed\")\n","    \n","# Messages\n","\n","def answer(update, context):\n","    \"\"\"Answer to the user message.\"\"\"\n","    global model_en\n","    global model_eu\n","    global tokenizer_en\n","    global tokenizer_eu\n","    global decoding_strategy\n","    input = update.message.text\n","    if lang == 'eu':\n","        sentence, output, attention = evaluate(input, model_eu, tokenizer_eu, decoding_strategy)\n","    else:\n","        sentence, output, attention = evaluate(input, model_en, tokenizer_en, decoding_strategy)\n","    update.message.reply_text(output.capitalize())\n","\n","def unknown(update, context):\n","    if lang == 'eu':\n","        text = \"Barkatu, komando hori ez dut ezagutzen. Komandoen zerrenda ikusteko /help erabili.\"\n","    else:\n","        text = \"Sorry, I didn't understand that command. Use /help to see a list of all comands.\"\n","    update.message.reply_text(text)\n","\n","# Errors\n","\n","def error(update, context):\n","    \"\"\"Log Errors caused by Updates.\"\"\"\n","    logger.warning('Update \"%s\" caused error \"%s\"', update, context.error)\n","\n","def main():\n","    \"\"\"Start the bot.\"\"\"\n","    # Create the Updater and pass it your bot's token.\n","    # Make sure to set use_context=True to use the new context based callbacks\n","    # Post version 12 this will no longer be necessary\n","    updater = Updater(TOKEN, use_context=True)\n","\n","    # Get the dispatcher to register handlers\n","    dp = updater.dispatcher\n","\n","    # on different commands - answer in Telegram\n","    dp.add_handler(CommandHandler(\"start\", start))\n","    dp.add_handler(CommandHandler(\"help\", help))\n","    dp.add_handler(CommandHandler(\"eu\", eu))\n","    dp.add_handler(CommandHandler(\"en\", en))\n","    dp.add_handler(CommandHandler('settings', settings))\n","    dp.add_handler(CommandHandler('language', language))\n","    dp.add_handler(CommandHandler('setlanguage', set_language))\n","    dp.add_handler(CommandHandler('decoding', decoding))\n","    dp.add_handler(CommandHandler('setdecoding', set_decoding))\n","    # callback handlers\n","    dp.add_handler(CallbackQueryHandler(decoding_callback, pattern=\"^top1|topk|multinomial$\"))\n","    dp.add_handler(CallbackQueryHandler(language_callback, pattern=\"^en|eu$\"))\n","    # conversation handlers\n","    '''conv_handler = ConversationHandler(\n","        entry_points=[CommandHandler('setdecoding', set_decoding)],\n","        states={\n","            FIRST: [CallbackQueryHandler(decoding_callback)]\n","        },\n","        fallbacks=[CommandHandler('setdecoding', set_decoding)]\n","    )'''\n","    # on noncommand message\n","    dp.add_handler(MessageHandler(Filters.text \u0026 (~Filters.command), answer))\n","    # on unknown commmand\n","    dp.add_handler(MessageHandler(Filters.command, unknown))\n","\n","    # log all errors\n","    dp.add_error_handler(error)\n","\n","    # Start the Bot\n","    updater.start_polling()\n","\n","    \"\"\"\n","    # Start the webhook\n","    NAME = \"The name of your app on Heroku\"\n","    # Port is given by Heroku\n","    PORT = os.environ.get('PORT')\n","    updater.start_webhook(listen=\"0.0.0.0\",\n","                          port=int(PORT),\n","                          url_path=TOKEN,\n","                          webhook_url=f\"https://{NAME}.herokuapp.com/{TOKEN}\")\n","    \"\"\"\n","\n","    # Run the bot until you press Ctrl-C or the process receives SIGINT,\n","    # SIGTERM or SIGABRT. This should be used most of the time, since\n","    # start_polling() is non-blocking and will stop the bot gracefully.\n","    updater.idle()\n","\n","\n","if __name__ == '__main__':\n","    main()"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"TelegramBot.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}